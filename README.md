# Customer Churn Analysis and Prediction

This project focuses on analyzing and predicting customer churn using data-driven approaches. It includes exploratory data analysis (EDA), statistical testing, data preprocessing, feature engineering, model selection, and hyperparameter tuning.

## ğŸ“Š Project Overview

The main goal of this project is to understand the patterns behind customer churn and build a predictive model that can help businesses retain their customers more effectively.

### Key Steps:
- Exploratory Data Analysis (EDA)
- Statistical Tests
- Data Preprocessing
- Feature Engineering
- Model Training and Evaluation
- Hyperparameter Tuning

## ğŸ› ï¸ Technologies Used

- **Python**  
- **Pandas, NumPy** â€“ data manipulation  
- **Matplotlib, Seaborn** â€“ data visualization  
- **Scikit-learn** â€“ modeling and evaluation  
- **XGBoost / CatBoostClassifier / RandomForestClassifier / GradientBoostingClassifier** â€“ main models  
- **Statsmodels / Scipy** â€“ statistical analysis  

## ğŸ“ˆ Exploratory Data Analysis

- Visualized churn distribution, correlations, and customer behavior
- Identified patterns and relationships between features and churn

## ğŸ“‹ Statistical Tests

- Conducted hypothesis testing to validate assumptions
- Used chi-squared tests, U Manna-Whitneya (Wilcoxona), Kruskal Wallis and Bonferroni Test depending on feature types

## âš™ï¸ Data Processing

- Handled missing values
- Encoded categorical variables
- Testing improvenent scaled numerical features

## ğŸ§  Feature Engineering

- Created new meaningful features based on domain knowledge
- Reduced dimensionality where necessary
- Selected the most important features using model-based techniques - MCA

## ğŸ¤– Model Development

- Compared multiple models: Logistic Regression, Random Forest, XGBoost, GradientBoosting itd.
- Evaluated using metrics like Accuracy, Precision, Recall, F1-Score, ROC-AUC
- Final model chosen based on balanced performance and interpretability

## ğŸ” Hyperparameter Tuning

- Used RandomizedSearchCV
- Optimized key parameters for best performance 

## ğŸš€ Results

- Achieved strong predictive performance:
  
Accuracy: 0.8611
Precision: 0.8546
Recall: 0.8961
F1 Score: 0.8748
ROC AUC: 0.9434
